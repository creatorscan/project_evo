# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain_cleaned/tdnn_1b_sp/configs/network.xconfig --config-dir exp/chain_cleaned/tdnn_1b_sp/configs/
# It contains the entire neural network, but with those
# components that would normally require fixed vectors/matrices
# read from disk, replaced with random initialization
# (this applies to the LDA-like transform and the
# presoftmax-prior-scale, if applicable).  This file
# is used only to work out the left-context and right-context
# of the network.

input-node name=ivector dim=100
input-node name=input dim=40
component name=lda type=FixedAffineComponent input-dim=220 output-dim=220
component-node name=lda component=lda input=Append(Offset(input, -1), input, Offset(input, 1), ReplaceIndex(ivector, t, 0))
component name=tdnn1.affine type=NaturalGradientAffineComponent input-dim=220 output-dim=725  max-change=0.75
component-node name=tdnn1.affine component=tdnn1.affine input=lda
component name=tdnn1.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn1.relu component=tdnn1.relu input=tdnn1.affine
component name=tdnn1.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn1.batchnorm component=tdnn1.batchnorm input=tdnn1.relu
component name=tdnn2.affine type=NaturalGradientAffineComponent input-dim=2900 output-dim=725  max-change=0.75
component-node name=tdnn2.affine component=tdnn2.affine input=Append(Offset(tdnn1.batchnorm, -1), tdnn1.batchnorm, Offset(tdnn1.batchnorm, 1), Offset(tdnn1.batchnorm, 2))
component name=tdnn2.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn2.relu component=tdnn2.relu input=tdnn2.affine
component name=tdnn2.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn2.batchnorm component=tdnn2.batchnorm input=tdnn2.relu
component name=tdnn3.affine type=NaturalGradientAffineComponent input-dim=2175 output-dim=725  max-change=0.75
component-node name=tdnn3.affine component=tdnn3.affine input=Append(Offset(tdnn2.batchnorm, -3), tdnn2.batchnorm, Offset(tdnn2.batchnorm, 3))
component name=tdnn3.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn3.relu component=tdnn3.relu input=tdnn3.affine
component name=tdnn3.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn3.batchnorm component=tdnn3.batchnorm input=tdnn3.relu
component name=tdnn4.affine type=NaturalGradientAffineComponent input-dim=2175 output-dim=725  max-change=0.75
component-node name=tdnn4.affine component=tdnn4.affine input=Append(Offset(tdnn3.batchnorm, -3), tdnn3.batchnorm, Offset(tdnn3.batchnorm, 3))
component name=tdnn4.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn4.relu component=tdnn4.relu input=tdnn4.affine
component name=tdnn4.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn4.batchnorm component=tdnn4.batchnorm input=tdnn4.relu
component name=tdnn5.affine type=NaturalGradientAffineComponent input-dim=2175 output-dim=725  max-change=0.75
component-node name=tdnn5.affine component=tdnn5.affine input=Append(Offset(tdnn4.batchnorm, -3), tdnn4.batchnorm, Offset(tdnn4.batchnorm, 3))
component name=tdnn5.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn5.relu component=tdnn5.relu input=tdnn5.affine
component name=tdnn5.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn5.batchnorm component=tdnn5.batchnorm input=tdnn5.relu
component name=tdnn6.affine type=NaturalGradientAffineComponent input-dim=2175 output-dim=725  max-change=0.75
component-node name=tdnn6.affine component=tdnn6.affine input=Append(Offset(tdnn5.batchnorm, -6), Offset(tdnn5.batchnorm, -3), tdnn5.batchnorm)
component name=tdnn6.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=tdnn6.relu component=tdnn6.relu input=tdnn6.affine
component name=tdnn6.batchnorm type=BatchNormComponent dim=725 target-rms=1.0
component-node name=tdnn6.batchnorm component=tdnn6.batchnorm input=tdnn6.relu
component name=prefinal-chain.affine type=NaturalGradientAffineComponent input-dim=725 output-dim=725  max-change=0.75
component-node name=prefinal-chain.affine component=prefinal-chain.affine input=tdnn6.batchnorm
component name=prefinal-chain.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=prefinal-chain.relu component=prefinal-chain.relu input=prefinal-chain.affine
component name=prefinal-chain.batchnorm type=BatchNormComponent dim=725 target-rms=0.5
component-node name=prefinal-chain.batchnorm component=prefinal-chain.batchnorm input=prefinal-chain.relu
component name=output.affine type=NaturalGradientAffineComponent input-dim=725 output-dim=5176 param-stddev=0.0 bias-stddev=0.0 max-change=1.5   
component-node name=output.affine component=output.affine input=prefinal-chain.batchnorm
output-node name=output input=output.affine objective=linear
component name=prefinal-xent.affine type=NaturalGradientAffineComponent input-dim=725 output-dim=725  max-change=0.75
component-node name=prefinal-xent.affine component=prefinal-xent.affine input=tdnn6.batchnorm
component name=prefinal-xent.relu type=RectifiedLinearComponent dim=725 self-repair-scale=1e-05
component-node name=prefinal-xent.relu component=prefinal-xent.relu input=prefinal-xent.affine
component name=prefinal-xent.batchnorm type=BatchNormComponent dim=725 target-rms=0.5
component-node name=prefinal-xent.batchnorm component=prefinal-xent.batchnorm input=prefinal-xent.relu
component name=output-xent.affine type=NaturalGradientAffineComponent input-dim=725 output-dim=5176 param-stddev=0.0 bias-stddev=0.0 max-change=1.5  learning-rate-factor=5.0  
component-node name=output-xent.affine component=output-xent.affine input=prefinal-xent.batchnorm
component name=output-xent.log-softmax type=LogSoftmaxComponent dim=5176
component-node name=output-xent.log-softmax component=output-xent.log-softmax input=output-xent.affine
output-node name=output-xent input=output-xent.log-softmax objective=linear
